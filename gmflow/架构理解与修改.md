
## 结构阅读
### 架构入口在main函数的 `modlue` 里
```python
    model = GMFlow(feature_channels=args.feature_channels,
                   num_scales=args.num_scales,
                   upsample_factor=args.upsample_factor,
                   num_head=args.num_head,
                   attention_type=args.attention_type,
                   ffn_dim_expansion=args.ffn_dim_expansion,
                   num_transformer_layers=args.num_transformer_layers,
                   ).to(device)
```
--feature_channels', default=128, type=int
--num_scales', default=1, type=int, help= '1表示了1/8'
--upsample_factor', default=8, type=int
--num_head', default=1, type=int
--attention_type', default='swin', type=str
'--ffn_dim_expansion', default=4, type=int
--num_transformer_layers', default=6, type=int

### 逻辑运行全在forward中

第一步对输入图片对的处理， 送入extract_feature

extract_feature 的处理是送入  CNNEncoder
在这里得到的是1/8 的特征图 ，这里没有多维特征，而extract_feature中提供的多维特征提取方式是冗余内容
features 是一个只包含一个元素的列表。这个唯一的元素是一个四维张量，形状为 [2*B, 128, H/8, W/8]
并把两个batch的特征分块分成feature 0 和 1

第二步对特征加入位置编码，在这里使用的是detr的绝对位置编码，很聪明的选择了meta的实现
这里主要是有个窗口的设置，我不知道它运行过程中实际上是怎样执行的,但从调用情况来看并没有执行这个窗口的位置编码情况
现在更推荐相对位置编码

第三步进transformer
```python
        #--num_transformer_layers', default=6, type=int
        # Transformer
        self.transformer = FeatureTransformer(num_layers=num_transformer_layers,
                                              d_model=feature_channels,
                                              nhead=num_head,
                                              attention_type=attention_type,
                                              ffn_dim_expansion=ffn_dim_expansion,
                                              )
        # Transformer attn_splits_list=None
            feature0, feature1 = self.transformer(feature0, feature1, attn_num_splits=attn_splits)


```


### 对这个代码的swin transformer 完全解读， 这里是对第三步 中transformer代码的解释

从swin transformer 的实现逻辑来看，将代码分为如下几个部分：
打成patch 更改维度 加入位置编码 算窗口自注意力 移动窗口 算窗口自注意力 窗口恢复 patchmerging 相当于下采样 再更改通道数
进入算窗口自注意力 移动窗口 算窗口自注意力 窗口恢复 patchmerging 这样的循环
直到由特征图接上对应任务头

但这里的代码有不少的改动
从入口开始看，这样大体逻辑是清楚的，逐层调用

```python
class FeatureTransformer(nn.Module):
    def __init__(self,
                 num_layers=6,
                 d_model=128,
                 nhead=1,
                 attention_type='swin',
                 ffn_dim_expansion=4,
                 **kwargs,
                 ):
        super(FeatureTransformer, self).__init__()
        self.attention_type = attention_type
        self.d_model = d_model
        self.nhead = nhead
        #↑ 这些是参数自定义
        #↓ 看到了 nn.ModuleList 要注意数据量的定义
        self.layers = nn.ModuleList([
            TransformerBlock(d_model=d_model,
                             nhead=nhead,
                             attention_type=attention_type,
                             ffn_dim_expansion=ffn_dim_expansion,
                             with_shift=True if attention_type == 'swin' and i % 2 == 1 else False,
                             )
            for i in range(num_layers)])

        for p in self.parameters():
            # 如果参数的维度 > 1 (通常意味着它是权重矩阵，而不是偏置向量)
            if p.dim() > 1:
                # 使用 Xavier 均匀分布来初始化这个参数
                nn.init.xavier_uniform_(p)

    def forward(self, feature0, feature1,
                attn_num_splits=None,
                **kwargs,
                ):

        # ...
```

```python
# `with_shift` 满足了条件才为真，否则为 else 的值
with_shift = True if attention_type == 'swin' and i % 2 == 1 else False
```
`i` 是 `for i in range(num_layers)])` 这里的内容

`for p in self.parameters():`
遍历 FeatureTransformer 模块中的每一个参数
self.parameters() 是 PyTorch `nn.Module` 自带的一个方法，它会返回一个迭代器，其中包含了该模块（FeatureTransformer）以及它所有子模块（如 TransformerBlock, nn.Linear, nn.LayerNorm 等）中所有需要学习的参数。
p 在每次循环中，就是一个具体的参数张量，比如 self.layers[0].self_attn.q_proj.weight 或者 self.layers[0].self_attn.q_proj.bias。
if p.dim() > 1:
`p.dim()` 会返回参数张量 p 的维度数量。
这是一个过滤器，用来区分权重（Weight）和偏置（Bias）。
权重张量：通常是矩阵或更高维的张量。例如，一个 nn.Linear 层的权重形状是 [out_features, in_features]，维度是2。p.dim() > 1 为 True。
偏置张量：通常是向量。例如，一个 nn.Linear 层的偏置形状是 [out_features]，维度是1。p.dim() > 1 为 False。
**所以，这行代码的逻辑是：“我们只对权重进行特殊初始化，而跳过偏置。”**
为什么跳过偏置？ 偏置通常被初始化为0，因为它们只是对输出进行平移，不存在像权重那样导致信号逐层放大或缩小的问题。
nn.init.xavier_uniform_(p)
这是实际执行初始化的函数。函数名末尾的下划线 _ 表示这是一个**in-place（原地）**操作，它会直接修改张量 p 的值。
Xavier (也称 Glorot) 初始化是一种非常著名且有效的权重初始化方法。
```python
class FeatureTransformer(nn.Module):
    def __init__(self,
                 num_layers=6,
                 d_model=128,
                 nhead=1,
                 attention_type='swin',
                 ffn_dim_expansion=4,
                 **kwargs,
                 ):
        super(FeatureTransformer, self).__init__()
    #...

    def forward(self, feature0, feature1,
                attn_num_splits=None,
                **kwargs,
                ):

        b, c, h, w = feature0.shape
        assert self.d_model == c
        #  [B, C, H, W] → [B, H*W, C]
        feature0 = feature0.flatten(-2).permute(0, 2, 1)  # [B, H*W, C]
        feature1 = feature1.flatten(-2).permute(0, 2, 1)  # [B, H*W, C]
        #~ 计算 swin transformer 的掩码
        if self.attention_type == 'swin' and attn_num_splits > 1:
            # global and refine use different number of splits
            window_size_h = h // attn_num_splits
            window_size_w = w // attn_num_splits

            # compute attn mask once
            shifted_window_attn_mask = generate_shift_window_attn_mask(
                input_resolution=(h, w),
                window_size_h=window_size_h,
                window_size_w=window_size_w,
                shift_size_h=window_size_h // 2,
                shift_size_w=window_size_w // 2,
                device=feature0.device,
            )  # [K*K, H/K*W/K, H/K*W/K]
        else:
            shifted_window_attn_mask = None

        # concat feature0 and feature1 in batch dimension to compute in parallel
        concat0 = torch.cat((feature0, feature1), dim=0)  # [2B, H*W, C]
        concat1 = torch.cat((feature1, feature0), dim=0)  # [2B, H*W, C]

        for layer in self.layers:
            concat0 = layer(concat0, concat1,
                            height=h,
                            width=w,
                            shifted_window_attn_mask=shifted_window_attn_mask,
                            attn_num_splits=attn_num_splits,
                            )

            # update feature1
            concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)

        feature0, feature1 = concat0.chunk(chunks=2, dim=0)  # [B, H*W, C]

        # reshape back
        feature0 = feature0.view(b, h, w, c).permute(0, 3, 1, 2).contiguous()  # [B, C, H, W]
        feature1 = feature1.view(b, h, w, c).permute(0, 3, 1, 2).contiguous()  # [B, C, H, W]

        return feature0, feature1
```


```python
        # concat feature0 and feature1 in batch dimension to compute in parallel
        concat0 = torch.cat((feature0, feature1), dim=0)  # [2B, H*W, C]
        concat1 = torch.cat((feature1, feature0), dim=0)  # [2B, H*W, C]

```
并行计算技巧？

### 计算光流的核心细节
```python
def global_correlation_softmax(feature0, feature1,
                               pred_bidir_flow=False,
                               ):
    # global correlation
    b, c, h, w = feature0.shape
    feature0 = feature0.view(b, c, -1).permute(0, 2, 1)  # [B, H*W, C]
    feature1 = feature1.view(b, c, -1)  # [B, C, H*W]
    
    correlation = torch.matmul(feature0, feature1).view(b, h, w, h, w) / (c ** 0.5)  # [B, H, W, H, W]

    # flow from softmax
    init_grid = coords_grid(b, h, w).to(correlation.device)  # [B, 2, H, W]
    grid = init_grid.view(b, 2, -1).permute(0, 2, 1)  # [B, H*W, 2]

    correlation = correlation.view(b, h * w, h * w)  # [B, H*W, H*W]

    if pred_bidir_flow:
        correlation = torch.cat((correlation, correlation.permute(0, 2, 1)), dim=0)  # [2*B, H*W, H*W]
        init_grid = init_grid.repeat(2, 1, 1, 1)  # [2*B, 2, H, W]
        grid = grid.repeat(2, 1, 1)  # [2*B, H*W, 2]
        b = b * 2

    prob = F.softmax(correlation, dim=-1)  # [B, H*W, H*W]

    correspondence = torch.matmul(prob, grid).view(b, h, w, 2).permute(0, 3, 1, 2)  # [B, 2, H, W]

    # when predicting bidirectional flow, flow is the concatenation of forward flow and backward flow
    flow = correspondence - init_grid

    return flow, prob

```
从这个函数直接得到预测光流，这个就是光流头，不过是按照1/8的特征进行的预测
**注意预测的细节**
- 由两个特征变换顺序计算`torch.matmul`来得到两个特征的相似性
- 得到初始网格坐标后（具体实现并没看）
- 计算特征内部的相似性 `softmax` 得到的相似性是概率，是为了加权求和的**权**
- 进行加权求和`torch.matmul` 得到预测的(x^,y^)
- 预测坐标减去初始坐标就是预测光流


## 架构修改

### 个人认为的改进点
起始通道数 从3 改成 1

cnn的第一次下采样卷积核 虽然都是7*7 我是否可以换？
绝对位置编码转换为相对位置编码？但是跳跃连接只是会在cnn中，这样改进可能也没啥用？

### cnn修改

- 保存cnn的多级特征图 2025年9月5日
- 添加utransnet的上采样部分 就是decoder  2025年9月5日
- 修改decoder的config 转换为参数 hidden_size decoder_channels n_skip skip_channels
` def __init__(self, hidden_size=128, decoder_channels=(128,96,64,16), n_skip=3,skip_channels=0 ):`
### cnn 架构
Model definition:
GMFlow(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): FeatureFlowAttention(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (upsampler): Sequential(
    (0): Conv2d(130, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 576, kernel_size=(1, 1), stride=(1, 1))
  )
)

### cnn 架构输出
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
CNNEncoder                               [12, 128, 64, 64]         --
├─Conv2d: 1-1                            [12, 64, 256, 256]        9,408
├─InstanceNorm2d: 1-2                    [12, 64, 256, 256]        --
├─ReLU: 1-3                              [12, 64, 256, 256]        --
├─Sequential: 1-4                        [12, 64, 256, 256]        --
│    └─ResidualBlock: 2-1                [12, 64, 256, 256]        --
│    │    └─Conv2d: 3-1                  [12, 64, 256, 256]        36,864
│    │    └─InstanceNorm2d: 3-2          [12, 64, 256, 256]        --
│    │    └─ReLU: 3-3                    [12, 64, 256, 256]        --
│    │    └─Conv2d: 3-4                  [12, 64, 256, 256]        36,864
│    │    └─InstanceNorm2d: 3-5          [12, 64, 256, 256]        --
│    │    └─ReLU: 3-6                    [12, 64, 256, 256]        --
│    │    └─ReLU: 3-7                    [12, 64, 256, 256]        --
│    └─ResidualBlock: 2-2                [12, 64, 256, 256]        --
│    │    └─Conv2d: 3-8                  [12, 64, 256, 256]        36,864
│    │    └─InstanceNorm2d: 3-9          [12, 64, 256, 256]        --
│    │    └─ReLU: 3-10                   [12, 64, 256, 256]        --
│    │    └─Conv2d: 3-11                 [12, 64, 256, 256]        36,864
│    │    └─InstanceNorm2d: 3-12         [12, 64, 256, 256]        --
│    │    └─ReLU: 3-13                   [12, 64, 256, 256]        --
│    │    └─ReLU: 3-14                   [12, 64, 256, 256]        --
├─Sequential: 1-5                        [12, 96, 128, 128]        --
│    └─ResidualBlock: 2-3                [12, 96, 128, 128]        --
│    │    └─Conv2d: 3-15                 [12, 96, 128, 128]        55,296
│    │    └─InstanceNorm2d: 3-16         [12, 96, 128, 128]        --
│    │    └─ReLU: 3-17                   [12, 96, 128, 128]        --
│    │    └─Conv2d: 3-18                 [12, 96, 128, 128]        82,944
│    │    └─InstanceNorm2d: 3-19         [12, 96, 128, 128]        --
│    │    └─ReLU: 3-20                   [12, 96, 128, 128]        --
│    │    └─Sequential: 3-21             [12, 96, 128, 128]        6,240
│    │    └─ReLU: 3-22                   [12, 96, 128, 128]        --
│    └─ResidualBlock: 2-4                [12, 96, 128, 128]        --
│    │    └─Conv2d: 3-23                 [12, 96, 128, 128]        82,944
│    │    └─InstanceNorm2d: 3-24         [12, 96, 128, 128]        --
│    │    └─ReLU: 3-25                   [12, 96, 128, 128]        --
│    │    └─Conv2d: 3-26                 [12, 96, 128, 128]        82,944
│    │    └─InstanceNorm2d: 3-27         [12, 96, 128, 128]        --
│    │    └─ReLU: 3-28                   [12, 96, 128, 128]        --
│    │    └─ReLU: 3-29                   [12, 96, 128, 128]        --
├─Sequential: 1-6                        [12, 128, 64, 64]         --
│    └─ResidualBlock: 2-5                [12, 128, 64, 64]         --
│    │    └─Conv2d: 3-30                 [12, 128, 64, 64]         110,592
│    │    └─InstanceNorm2d: 3-31         [12, 128, 64, 64]         --
│    │    └─ReLU: 3-32                   [12, 128, 64, 64]         --
│    │    └─Conv2d: 3-33                 [12, 128, 64, 64]         147,456
│    │    └─InstanceNorm2d: 3-34         [12, 128, 64, 64]         --
│    │    └─ReLU: 3-35                   [12, 128, 64, 64]         --
│    │    └─Sequential: 3-36             [12, 128, 64, 64]         12,416
│    │    └─ReLU: 3-37                   [12, 128, 64, 64]         --
│    └─ResidualBlock: 2-6                [12, 128, 64, 64]         --
│    │    └─Conv2d: 3-38                 [12, 128, 64, 64]         147,456
│    │    └─InstanceNorm2d: 3-39         [12, 128, 64, 64]         --
│    │    └─ReLU: 3-40                   [12, 128, 64, 64]         --
│    │    └─Conv2d: 3-41                 [12, 128, 64, 64]         147,456
│    │    └─InstanceNorm2d: 3-42         [12, 128, 64, 64]         --
│    │    └─ReLU: 3-43                   [12, 128, 64, 64]         --
│    │    └─ReLU: 3-44                   [12, 128, 64, 64]         --
├─Conv2d: 1-7                            [12, 128, 64, 64]         16,512
==========================================================================================
Total params: 1,049,120
Trainable params: 1,049,120
Non-trainable params: 0
Total mult-adds (G): 212.98
==========================================================================================
Input size (MB): 37.75
Forward/backward pass size (MB): 3070.23
Params size (MB): 4.20
Estimated Total Size (MB): 3112.18


### cnn 卷积核
Layer: conv1
  |-> Weight Shape: torch.Size([64, 3, 7, 7])
  |-> In Channels: 3, Out Channels: 64
  |-> Inferred Kernel Size: (7, 7)

Layer: layer1.0.conv1
  |-> Weight Shape: torch.Size([64, 64, 3, 3])
  |-> In Channels: 64, Out Channels: 64
  |-> Inferred Kernel Size: (3, 3)

Layer: layer1.0.conv2
  |-> Weight Shape: torch.Size([64, 64, 3, 3])
  |-> In Channels: 64, Out Channels: 64
  |-> Inferred Kernel Size: (3, 3)

Layer: layer1.1.conv1
  |-> Weight Shape: torch.Size([64, 64, 3, 3])
  |-> In Channels: 64, Out Channels: 64
  |-> Inferred Kernel Size: (3, 3)

Layer: layer1.1.conv2
  |-> Weight Shape: torch.Size([64, 64, 3, 3])
  |-> In Channels: 64, Out Channels: 64
  |-> Inferred Kernel Size: (3, 3)

Layer: layer2.0.conv1
  |-> Weight Shape: torch.Size([96, 64, 3, 3])
  |-> In Channels: 64, Out Channels: 96
  |-> Inferred Kernel Size: (3, 3)

Layer: layer2.0.conv2
  |-> Weight Shape: torch.Size([96, 96, 3, 3])
  |-> In Channels: 96, Out Channels: 96
  |-> Inferred Kernel Size: (3, 3)

Layer: layer2.0.downsample.0
  |-> Weight Shape: torch.Size([96, 64, 1, 1])
  |-> In Channels: 64, Out Channels: 96
  |-> Inferred Kernel Size: (1, 1)

Layer: layer2.1.conv1
  |-> Weight Shape: torch.Size([96, 96, 3, 3])
  |-> In Channels: 96, Out Channels: 96
  |-> Inferred Kernel Size: (3, 3)

Layer: layer2.1.conv2
  |-> Weight Shape: torch.Size([96, 96, 3, 3])
  |-> In Channels: 96, Out Channels: 96
  |-> Inferred Kernel Size: (3, 3)

Layer: layer3.0.conv1
  |-> Weight Shape: torch.Size([128, 96, 3, 3])
  |-> In Channels: 96, Out Channels: 128
  |-> Inferred Kernel Size: (3, 3)

Layer: layer3.0.conv2
  |-> Weight Shape: torch.Size([128, 128, 3, 3])
  |-> In Channels: 128, Out Channels: 128
  |-> Inferred Kernel Size: (3, 3)

Layer: layer3.0.downsample.0
  |-> Weight Shape: torch.Size([128, 96, 1, 1])
  |-> In Channels: 96, Out Channels: 128
  |-> Inferred Kernel Size: (1, 1)

Layer: layer3.1.conv1
  |-> Weight Shape: torch.Size([128, 128, 3, 3])
  |-> In Channels: 128, Out Channels: 128
  |-> Inferred Kernel Size: (3, 3)

Layer: layer3.1.conv2
  |-> Weight Shape: torch.Size([128, 128, 3, 3])
  |-> In Channels: 128, Out Channels: 128
  |-> Inferred Kernel Size: (3, 3)

Layer: conv2
  |-> Weight Shape: torch.Size([128, 128, 1, 1])
  |-> In Channels: 128, Out Channels: 128
  |-> Inferred Kernel Size: (1, 1)


### transformer 层的输出
============================================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape
============================================================================================================================================
FeatureTransformer                       --                        [12, 128, 64, 64]         --                        --
├─ModuleList: 1-1                        --                        --                        --                        --
│    └─TransformerBlock: 2-1             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-1        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-1             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-2             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-3             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-4             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-5          [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-2        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-6             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-7             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-8             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-9             [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-10         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-11        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-1        [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-2          [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-3        [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-12         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    └─TransformerBlock: 2-2             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-3        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-13            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-14            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-15            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-16            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-17         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-4        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-18            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-19            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-20            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-21            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-22         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-23        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-4        [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-5          [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-6        [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-24         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    └─TransformerBlock: 2-3             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-5        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-25            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-26            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-27            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-28            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-29         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-6        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-30            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-31            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-32            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-33            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-34         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-35        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-7        [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-8          [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-9        [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-36         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    └─TransformerBlock: 2-4             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-7        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-37            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-38            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-39            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-40            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-41         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-8        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-42            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-43            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-44            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-45            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-46         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-47        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-10       [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-11         [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-12       [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-48         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    └─TransformerBlock: 2-5             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-9        [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-49            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-50            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-51            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-52            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-53         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-10       [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-54            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-55            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-56            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-57            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-58         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-59        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-13       [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-14         [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-15       [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-60         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    └─TransformerBlock: 2-6             [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    └─TransformerLayer: 3-11       [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-61            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-62            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-63            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-64            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-65         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    └─TransformerLayer: 3-12       [24, 4096, 128]           [24, 4096, 128]           --                        --
│    │    │    └─Linear: 4-66            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-67            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-68            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─Linear: 4-69            [24, 4096, 128]           [24, 4096, 128]           16,384                    --
│    │    │    └─LayerNorm: 4-70         [24, 4096, 128]           [24, 4096, 128]           256                       --
│    │    │    └─Sequential: 4-71        [24, 4096, 256]           [24, 4096, 128]           --                        --
│    │    │    │    └─Linear: 5-16       [24, 4096, 256]           [24, 4096, 1024]          262,144                   --
│    │    │    │    └─GELU: 5-17         [24, 4096, 1024]          [24, 4096, 1024]          --                        --
│    │    │    │    └─Linear: 5-18       [24, 4096, 1024]          [24, 4096, 128]           131,072                   --
│    │    │    └─LayerNorm: 4-72         [24, 4096, 128]           [24, 4096, 128]           256                       --
============================================================================================================================================
Total params: 3,150,336
Trainable params: 3,150,336
Non-trainable params: 0
Total mult-adds (M): 75.61
============================================================================================================================================
Input size (MB): 50.33
Forward/backward pass size (MB): 12079.60
Params size (MB): 12.60
Estimated Total Size (MB): 12142.53
============================================================================================================================================